{
  "name": "NMSO",
  "tagline": "Naive Multi-Scale Optimization Algorithm for bound-constrained black-box global optimization problems",
  "body": "### Welcome to NMSO.\r\nThis page hosts the MATLAB code for the Naive Multi-Scale Optimization (NMSO) algorithm to appear in, \"[A Naive Multi-Scale Algorithm for Global Optimization Problems](http://www.sciencedirect.com/science/article/pii/S0020025516305370)\", by Abdullah Al-Dujaili and S. Suresh.\r\n\r\nThis algorithm has secured the **third** place out of **28** algorithms in the BBComp competition in GECCO'15.\r\nFor more details, please refer to [this](http://bbcomp.ini.rub.de/results/BBComp2015GECCO/summary.html).\r\n### Quick Demo\r\nFire MATLAB and run the following:\r\n~~~\r\nrunDemo\r\n~~~\r\nThis will walk you through a short demo of NMSO in action optimizing a function in 1-D and 2-D. You may want to toy with the algorithm's parameters (e.g., alpha and beta to get a better performance depending on the problem at hand).\r\n\r\n### How to use NMSO\r\n\r\nNMSO has been designed for Black-box Bound-constrained Global Optimization problems. The following would minimize a spherical function whose optimal solution at x=[0.231 0.231] in a 2-D problem space, with the variables being limited to [0,1], using a function evaluation budget of 1000.\r\n\r\n~~~\r\nfunc = @(x) sum((x-0.231).^2);\r\ndim = 2;\r\nmaxRange = 1;\r\nminRange = 0;\r\nnumEvaluations = 1000;\r\nftarget = 0;\r\n[yBest,xBest]= NMSO(ftarget, func, numEvaluations, dim, maxRange, minRange, 0);\r\n~~~\r\n\r\n### Citation\r\n\r\nIf you write a scientific paper describing research that made use of this code, please cite the following paper:\r\n\r\n~~~\r\n@article{AlDujaili2016294,\r\ntitle = \"A Naive multi-scale search algorithm for global optimization problems \",\r\njournal = \"Information Sciences \",\r\nvolume = \"372\",\r\nnumber = \"\",\r\npages = \"294 - 312\",\r\nyear = \"2016\",\r\nnote = \"\",\r\nissn = \"0020-0255\",\r\ndoi = \"http://dx.doi.org/10.1016/j.ins.2016.07.054\",\r\nurl = \"http://www.sciencedirect.com/science/article/pii/S0020025516305370\",\r\nauthor = \"Abdullah Al-Dujaili and S. Suresh\",\r\nkeywords = \"Black-box optimization\",\r\nkeywords = \"Global optimization\",\r\nkeywords = \"Derivative-free optimization\",\r\nkeywords = \"Partitioning-based\",\r\nkeywords = \"Optimistic algorithms\",\r\nkeywords = \"Finite-time analysis \",\r\nabstract = \"Abstract This paper proposes a multi-scale search algorithm for solving global optimization problems given a finite number of function evaluations. We refer to this algorithm as the Naive Multi-scale Search Optimization (NMSO). \\{NMSO\\} looks for the optimal solution by optimistically partitioning the search space over multiple scales in a hierarchical fashion. Based on a weak assumption about the function smoothness, we present a theoretical analysis on its finite-time and asymptotic convergence. An empirical assessment of the algorithm has been conducted on the noiseless Black-Box Optimization Benchmarking (BBOB) testbed and compared with the state-of-the-art optimistic as well as stochastic algorithms. Moreover, the efficacy of \\{NMSO\\} has been validated on the black-box optimization competition within the GECCOâ€™15 conference where it has secured the third place out of twenty-eight participating algorithms. Overall, \\{NMSO\\} is suitable for problems with limited function evaluations, low-dimensionality search space, and objective functions that are separable or multi-modal. Otherwise, it is comparable with the top performing algorithms. \"\r\n}\r\n~~~\r\n",
  "google": "UA-68645681-3",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}